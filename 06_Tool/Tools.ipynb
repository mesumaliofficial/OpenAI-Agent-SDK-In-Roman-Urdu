{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¹ OpenAI Agents Tools**"
      ],
      "metadata": {
        "id": "GqanKzXAa7qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** OpenAI Agents Setup in Google Colab**\n",
        "\n",
        "Sab se pehle OpenAI Agents aur async code ke liye zaroori libraries install karen:\n",
        "\n",
        "```python\n",
        "!pip install openai-agents\n",
        "!pip install nest_asyncio\n",
        "!pip install typing_extensions\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "qnbb0Fiu2KFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-agents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "souTtNkh2Np-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab ky andar Agent ko Asynchronous mein chalanay ky leye **nest_asyncio** ki library install karna paryge"
      ],
      "metadata": {
        "id": "dRokHEIOrjfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hcw5IbKJrg7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Simple Async Agent Banana**"
      ],
      "metadata": {
        "id": "pj4A67m02cwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"How are you\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "-AOkPQZL5WSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Pyhton Function Tool Agent**"
      ],
      "metadata": {
        "id": "e3S-oqjXs8lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather]\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"what is the weather in karachi\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "        print(json.dumps(tool.params_json_schema, indent=4))\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "iKGAaW52tICl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Custom Function Tool with TypedDict and Pydantic**\n",
        "---\n",
        "Kabhi Kabhi hame python function tool nh chahiye hota tw hum apna khud ka\n",
        "custom tool bhi bana sakty hain **FunctionTool** ka use karky"
      ],
      "metadata": {
        "id": "NfNo92PAw2tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing_extensions"
      ],
      "metadata": {
        "id": "aIIWRUsO50tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, FunctionTool, RunContextWrapper\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "# Result ka format define karte hain: hum words aur letters ki ginti return karenge (dono integers)\n",
        "class WordsAndLettersCounter(TypedDict):\n",
        "  words: int\n",
        "  letters: int\n",
        "\n",
        "# Input ka format define karte hain: sirf ek field \"text\" chahiye humein, jo string hogi\n",
        "class CounterInput(BaseModel):\n",
        "  text: str\n",
        "\n",
        "# Yeh async function hai jo tool ka asli kaam karega\n",
        "async def counter_logic(ctx: RunContextWrapper[str], args: str) -> WordsAndLettersCounter:\n",
        "  # args jo JSON string hai usko CounterInput model ke mutabiq parse aur validate karte hain\n",
        "  parsed = CounterInput.model_validate_json(args) # args ko check karta hai ke sahi format mein hai ya nahi\n",
        "  words = parsed.text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(len(letter) for letter in parsed.text)\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "counter_tool = FunctionTool(\n",
        "    name=\"words_letter_counter\", # tool ka naam.\n",
        "    description=\"This tool counts the number of words and letters in a given text.\", #Tool kya karta hai, LLM ko samjhane ke liye.\n",
        "    params_json_schema=CounterInput.model_json_schema(), # yahan auto create kara hay json schmea manually bhi kar sakty hain.\n",
        "    on_invoke_tool=counter_logic # ye json string mein recieve karta hay ToolContext aur return string mein karta hay.\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  agent = Agent(\n",
        "      name = \"Jarvis\",\n",
        "      instructions = \"You are a helpful assistant. if your asks about words and leters count so call the counter Tool\",\n",
        "      tools=[counter_tool]\n",
        "  )\n",
        "\n",
        "  result = await Runner.run(\n",
        "      starting_agent=agent,\n",
        "      input=\"how many letters and words are in this sentence 'my name is Mesum Ali.'\",\n",
        "      run_config=config\n",
        "  )\n",
        "\n",
        "  print(result.final_output)\n",
        "  for tool in agent.tools:\n",
        "    if tool:\n",
        "      print(tool.name)\n",
        "      print(tool.description)\n",
        "      print(json.dumps(tool.params_json_schema, indent=4))\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "YZESvcxXw-Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”¸Agents as tools**"
      ],
      "metadata": {
        "id": "pfoDlT2QQvGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "\n",
        "    Urdu_Agent = Agent(\n",
        "        name=\"Urdu_Agent\",\n",
        "        instructions=\"You translate the user's message to Urdu, no explanations, just translation.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    Roman_Urdu_Agent = Agent(\n",
        "        name=\"Roman_Urdu_Agent\",\n",
        "        instructions=\"You translate the user's message to Roman Urdu, no explanations, just translation.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    Boss = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=(\n",
        "            \"You are an assistant that translates text. \"\n",
        "            \"If the user wants translation to Urdu, call the 'translate_to_urdu' tool with the user's text. \"\n",
        "            \"If the user wants translation to Roman Urdu, call the 'translate_to_roman_urdu' tool with the user's text. \"\n",
        "            \"Only respond with the output from the tools.\"\n",
        "        ),\n",
        "        tools=[\n",
        "            Urdu_Agent.as_tool(\n",
        "                tool_name=\"translate_to_urdu\",\n",
        "                tool_description=\"This tool translates the user's message to Urdu\"\n",
        "            ),\n",
        "            Roman_Urdu_Agent.as_tool(\n",
        "                tool_name=\"translate_to_roman_urdu\",\n",
        "                tool_description=\"This tool translates the user's message to Roman Urdu\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Corrected input examples:\n",
        "    input_text = \"Translate 'Hello, how are you?' to Roman Urdu.\"\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=Boss,\n",
        "        input=input_text,\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()\n"
      ],
      "metadata": {
        "id": "KwpGnhWXQyDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Custom output extraction**\n",
        "\n",
        "---\n",
        "kuch cases mein hum chahty hain tool-agents ka output boss agent ko return karny sy phely modify keya jaye. lekin isky leye apko OpenAI ki api key use karna paryge"
      ],
      "metadata": {
        "id": "ZmkQlSAwbpoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, OpenAIChatCompletionsModel, RunConfig, model_settings, AsyncOpenAI, RunResult, ToolCallOutputItem\n",
        "import nest_asyncio\n",
        "import os\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ==== Set your api key ====\n",
        "openai_api_key = \"\"\n",
        "\n",
        "# ==== Create OpenAI Client ====\n",
        "client = AsyncOpenAI(\n",
        "    api_key=openai_api_key\n",
        ")\n",
        "\n",
        "# ==== Create OpenAI Model ====\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "# ==== Create Run Config ====\n",
        "# ==== ye sab tokens set karny ky leye keya hay taky limited tokens use ho. ====\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True,\n",
        "    model_settings=model_settings.ModelSettings(max_tokens=100)\n",
        ")\n",
        "\n",
        "# ==== Data Agent ====\n",
        "data_agent = Agent(\n",
        "    name=\"Assistant\",\n",
        "    instructions=(\n",
        "        \"You are a helpful assistant. \"\n",
        "        \"When called, return ONLY a valid JSON object, no extra text. \"\n",
        "        \"Example: {\\\"name\\\": \\\"John\\\", \\\"age\\\": 30}\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# ==== Custom Output Extractor ====\n",
        "async def extract_json_payload(run_result: RunResult):\n",
        "  for item in reversed(run_result.new_items):\n",
        "    if isinstance(item, ToolCallOutputItem) and item.output.strip().startswith(\"{\"):\n",
        "      return item.output.strip()\n",
        "  return {}\n",
        "\n",
        "json_tool = data_agent.as_tool(\n",
        "    tool_name=\"get_data_json\",\n",
        "    tool_description=\"Run the data agent and return only its JSON payload\",\n",
        "    custom_output_extractor=extract_json_payload\n",
        ")\n",
        "\n",
        "# ==== Orchestrator Agent ====\n",
        "orchestrator_agent = Agent(\n",
        "    name=\"Boss_Agent\",\n",
        "    instructions=(\n",
        "        \"You MUST call the tool `extract_json_payload` exactly once with the user request as input. \"\n",
        "        \"Do NOT answer directly. Do NOT respond with any other text.\"\n",
        "    ),\n",
        "    tools=[json_tool],\n",
        ")\n",
        "\n",
        "# ==== Main Runner ====\n",
        "async def main():\n",
        "  result = await Runner.run(\n",
        "      starting_agent=orchestrator_agent,\n",
        "      input=\"give me the dummy jsom\",\n",
        "      run_config=config\n",
        "  )\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "RBTLZfnvb3zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Forcing tool use**\n",
        "Example => 01: LLM sirf wahi tool use karega jo aap batayenge.\n"
      ],
      "metadata": {
        "id": "y_RfPakFa6Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool, ModelSettings\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        model_settings=ModelSettings(tool_choice=\"words_and_letters_counter\")\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"what is the weather in karachi\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "87ITtvoldw_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Forcing tool use**\n",
        "Example => 02: Ab LLM koi tool use nahi karega.\n"
      ],
      "metadata": {
        "id": "mtPOYB_Qi5vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool, ModelSettings\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        model_settings=ModelSettings(tool_choice=\"none\")\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"what is the weather in karachi\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "s8K8ZTuUi5fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Forcing tool use**\n",
        "Example => 03: LLM ab har sitaution mein kum az km ek tool use karega, aur ye khud decide karega keh konsa tool use karna chahiye.\n"
      ],
      "metadata": {
        "id": "e2W55k0VjtIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool, ModelSettings\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        model_settings=ModelSettings(tool_choice=\"required\")\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"hello how are you\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "qhNrLaDxjykL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Forcing tool use**\n",
        "Example => 04: LLM ab khud decide karyga tool use karna chahiye ya nh. by default ye behavior `auto` hota hay\n"
      ],
      "metadata": {
        "id": "YnhbBnaDkTcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool, ModelSettings\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        model_settings=ModelSettings(tool_choice=\"auto\")\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"hello how are you\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "    # Checking the tool details:\n",
        "    # Agent returns output as a plain string.\n",
        "    # Each tool provides its output in JSON schema format,\n",
        "    # but the agent converts it into a plain string before returning it.\n",
        "    for tool in agent.tools:\n",
        "      if tool:\n",
        "        print(tool.name)\n",
        "        print(tool.description)\n",
        "\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "gyXM0t58kY80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Tool Use Behavior**\n",
        "Example => 01: `stop_on_first_tool` LLM ko pehle tool ka output milty hi execution stop kar dena, yani jo bhi pehla tool output dega, wahi directly user ko bhejna, LLM ko wapas pass na karna.\n",
        "\n",
        "---\n",
        "`tool_use_behavior` â†’ yeh property control karti hai ki jab agent koi tool use kare, to uska output LLM ko wapas kaise (ya kab) diya jaye."
      ],
      "metadata": {
        "id": "l-yv4AKwJJEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        tool_use_behavior=\"stop_on_first_tool\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"give me the info karachi weather. and 'hello how are you' count the letters in this sentence\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "M5clNUsZxlik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Tool Use Behavior**\n",
        "Example => 02: `run_llm_again` Yeh tool ka Default behavior hay, Ye tool ke output leker LLM ky zariye process karky final response ready karta hay."
      ],
      "metadata": {
        "id": "RU513KsYCKKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        tool_use_behavior=\"run_llm_again\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"give me the info karachi weather. and 'hello how are you' count the letters in this sentence\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "4UCn0ZqwCR7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Tool Use Behavior**\n",
        "Example => 03: `StopAtTools(stop_at_tool_names=[...])` Agar koi spcific tool call hota hay tw ye usi waqt rukh jata hay aur usi tool ka output final response ky tor per use karta hay."
      ],
      "metadata": {
        "id": "YXsvfifTEcCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool, StopAtTools\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        tool_use_behavior=StopAtTools(stop_at_tool_names=[\"fetch_weather\"]),\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"give me the info karachi weather. and 'hello how are you' count the letters in this sentence\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "qo7DkYECEqZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”¸Tool Use Behavior**\n",
        "Example => 04: `ToolsToFinalOutputFunction` Ek custom function hota hay jo tools ky results ko process karta hay aur yeh decide karta hay keh LLm ko continue karna hay ya nh."
      ],
      "metadata": {
        "id": "OOeCDq6DGw9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, function_tool, StopAtTools, RunContextWrapper, FunctionToolResult, ToolsToFinalOutputResult\n",
        "from typing import List, Any\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAzjfiUtoEpGMp1hjSlkhfEakL6eoQCkec\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "@function_tool\n",
        "def fetch_weather(city: str) -> str:\n",
        "  \"\"\"\n",
        "  This is fetch weather tool\n",
        "  \"\"\"\n",
        "  return f\"The weather in {city} is cloudy.\"\n",
        "\n",
        "@function_tool\n",
        "def words_and_letters_counter(text: str):\n",
        "  \"\"\"\n",
        "  This is words and letters counter tool\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  words_count = len(words)\n",
        "  letters_count = sum(1 for letter in text if letter.isalpha())\n",
        "  return { \"words\": words_count, \"letters\": letters_count }\n",
        "\n",
        "def custom_tool_handler(ctx: RunContextWrapper, tools_results: List[FunctionToolResult]) -> ToolsToFinalOutputResult:\n",
        "  \"\"\"Process tool results to decide the final output\"\"\"\n",
        "  for result in tools_results:\n",
        "    if result.output and \"cloudy\" in result.output:\n",
        "      return ToolsToFinalOutputResult(\n",
        "          is_final_output=True,\n",
        "          final_output=f\"Final Weather: {result.output}\"\n",
        "      )\n",
        "  return ToolsToFinalOutputResult(\n",
        "      is_final_output=False,\n",
        "      final_output=None\n",
        "  )\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Asistant\",\n",
        "        instructions=\"You are a helpfull asistant.\",\n",
        "        tools=[fetch_weather, words_and_letters_counter],\n",
        "        tool_use_behavior=custom_tool_handler\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"give me the info karachi weather. and 'hello how are you' count the letters in this sentence\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "HNONzZaoHVxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}