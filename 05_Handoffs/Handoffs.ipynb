{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 **Agents → Handoffs**"
      ],
      "metadata": {
        "id": "Pcxl4u3lyHBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y openai\n",
        "!pip install --upgrade openai\n",
        "!pip install --upgrade openai-agents\n",
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijkIHPQ8yLBG",
        "outputId": "d185effa-5ace-4701-8a47-e81274e92192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: openai 1.108.0\n",
            "Uninstalling openai-1.108.0:\n",
            "  Successfully uninstalled openai-1.108.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-1.109.1\n",
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.14.1)\n",
            "Requirement already satisfied: openai<2,>=1.107.1 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.109.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.32.4)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (4.15.0)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.10.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.48.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n",
            "Downloading openai_agents-0.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: types-requests, colorama, griffe, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.14.0 openai-agents-0.3.2 types-requests-2.32.4.20250913\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Simple Handoffs**\n",
        "**Example => 01:** Simple Handoffs"
      ],
      "metadata": {
        "id": "ULqylSj0yOIH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvL0PYqduQdt",
        "outputId": "42e31d32-6c13-47f3-bc24-770ee426a262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: mujhy flight ka ticket book karwana hay\n",
            "Agent: Booking Agent\n",
            "Output: Okay, I can help you with that. To book your flight, I need some information.  Please tell me:\n",
            "\n",
            "*   **Where are you flying from?** (Departure city/airport)\n",
            "*   **Where are you flying to?** (Destination city/airport)\n",
            "*   **What date would you like to travel?**\n",
            "*   **Do you want a one-way or round-trip ticket?**\n",
            "*   **If round-trip, what is your return date?**\n",
            "*   **How many passengers are there?** (Adults, children, infants)\n",
            "*   **Do you have any preferred airlines?**\n",
            "*   **Do you have any preferences for the time of day you'd like to fly?** (Morning, afternoon, evening)\n",
            "*   **Do you have a preferred class of service?** (Economy, Business, First Class)\n",
            "\n",
            "Once I have this information, I can start searching for flights for you.\n",
            "\n",
            "You: sorry ticket cancel karwa kar refund karwana hay\n",
            "Agent: Refund Agent\n",
            "Output: Okay, I'm transferring you to a Refund Agent who can help you cancel your tickets and process your refund. Please be ready to provide them with your booking details (like booking reference number and passenger name).\n",
            "\n",
            "You: exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "from typing import Any\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyCIgATnpmw6AM6qvpLF9MALMLt4-dixWtQ\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "booking_agent = Agent(name=\"Booking Agent\", instructions=\"Help the user for bokking the flight tickets.\", model=model )\n",
        "refund_agent = Agent(name=\"Refund Agent\", instructions=\"Help the user for refund the flight tickets.\", model=model )\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage agent\",\n",
        "    instructions=\"\"\"\n",
        "        \"Help the user with their question.\",\n",
        "        \"If the ask about booking, Hand off to the booking agent.\",\n",
        "        \"If the ask about refunds, Hand off to the booking agent.\"\n",
        "    \"\"\",\n",
        "    handoffs=[booking_agent, refund_agent],\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "      print(\"Exiting...\")\n",
        "      break\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=triage_agent,\n",
        "        input=user_input,\n",
        "        run_config=config\n",
        "    )\n",
        "    print(f\"Agent: {result.last_agent.name}\")\n",
        "    print(f\"Output: {result.final_output}\")\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Custom Handoff**\n",
        "**Example => 02:** Custom Handoffs with handoff() Function"
      ],
      "metadata": {
        "id": "pF7PMaUR3iSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, handoff\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "billing_agent = Agent(name=\"Billing Agent\", instructions=\"...\")\n",
        "refund_agent = Agent(name=\"Refund Agent\", instructions=\"...\")\n",
        "\n",
        "custom_billing_handoff = handoff(\n",
        "    agent=billing_agent,\n",
        "    tool_name_override=\"transfer_to_billing_specialist\",\n",
        "    tool_description_override=\"Transfer the conversation to a billing specialist to resolve billing issues.\"\n",
        ")\n",
        "\n",
        "triage_agent_custom = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=(\n",
        "        \"You are a helpful customer support assistant. \"\n",
        "        \"Use the 'transfer_to_billing_specialist' tool for billing questions. \"\n",
        "        \"Use the default handoff for refund questions.\"\n",
        "    ),\n",
        "    handoffs=[custom_billing_handoff, refund_agent]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        userInput = input(\"You: \")\n",
        "\n",
        "        if userInput.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        result = await Runner.run(\n",
        "            starting_agent=triage_agent_custom,\n",
        "            input=userInput,\n",
        "        )\n",
        "\n",
        "        print(f\"Current Agent: {result.last_agent}\")\n",
        "        print(f\"Output: {result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "F-3mB3sNE9n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Handoff Input**\n",
        "**Example => 03:** Handoff Input"
      ],
      "metadata": {
        "id": "Dk-mhOO5xT8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, RunContextWrapper, handoff\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "from pydantic import BaseModel\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "class EscalationReason(BaseModel):\n",
        "    reason: str\n",
        "\n",
        "async def on_escalate(ctx: RunContextWrapper[None], input_data: EscalationReason):\n",
        "    print(f\"Handoff invoked with result {input_data.reason}\")\n",
        "\n",
        "escalation_agent = Agent(\n",
        "    name=\"escalation_agent\",\n",
        "    instructions=\"I handle high-priority customer issues.\",\n",
        ")\n",
        "\n",
        "escalate_handoff = handoff(\n",
        "    agent=escalation_agent,\n",
        "    on_handoff=on_escalate,\n",
        "    input_type=EscalationReason\n",
        ")\n",
        "\n",
        "main_agent = Agent(\n",
        "    name=\"Main Agent\",\n",
        "    instructions=(\n",
        "        \"You are a customer service agent. If the user's issue is complex and requires special attention, \"\n",
        "        \"escalate the conversation to the 'Escalation Agent'. \"\n",
        "        \"You must provide a reason for escalation and its priority.\"\n",
        "    ),\n",
        "    handoffs=[escalate_handoff]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        userInput = input(\"You: \")\n",
        "\n",
        "        if userInput.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        result = await Runner.run(\n",
        "            starting_agent=main_agent,\n",
        "            input=userInput,\n",
        "        )\n",
        "\n",
        "        print(f\"Current Agent: {result.last_agent.name}\")\n",
        "        print(f\"Output: {result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "vvLdsdg9xhvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Handoff**\n",
        "**Example => 04:** HandoffInputData se hum conversation ke alag alag parts ko kaise dekhte hain\n"
      ],
      "metadata": {
        "id": "MgmFrZW55BAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, HandoffInputData, handoff\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "async def log_handoff_data(handoff_input_data: HandoffInputData):\n",
        "\n",
        "    # 1. input_history: Conversation shuru hone se pehle ki history.\n",
        "    print(\"--- 1. Input History ---\")\n",
        "    print(handoff_input_data.input_history)\n",
        "\n",
        "    # 2. pre_handoff_items: Pichle messages jab handoff shuru nahi hua tha.\n",
        "    print(\"\\n--- 2. Pre-Handoff Items ---\")\n",
        "    print(handoff_input_data.pre_handoff_items)\n",
        "\n",
        "    # 3. new_items: Current turn mein bane items (handoff call bhi ismein hota hai).\n",
        "    print(\"\\n--- 3. New Items (Handoff Call) ---\")\n",
        "    for item in handoff_input_data.new_items:\n",
        "        print(f\"Type: {type(item).__name__}, Content: {item}\")\n",
        "\n",
        "    # Data ko bina change kiye wapas kar diya\n",
        "    return handoff_input_data\n",
        "\n",
        "\n",
        "target_agent = Agent(name=\"Target Agent\")\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=\"Handoff to the target agent.\",\n",
        "    handoffs=[\n",
        "        handoff(\n",
        "            agent=target_agent,\n",
        "            input_filter=log_handoff_data\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        userInput = input(\"You: \")\n",
        "\n",
        "        if userInput.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        result = await Runner.run(\n",
        "            starting_agent=triage_agent,\n",
        "            input=userInput,\n",
        "        )\n",
        "\n",
        "        print(f\"Current Agent: {result.last_agent.name}\")\n",
        "        print(f\"Output: {result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "6r2fXeCf5KC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Handoff Input Filter**\n",
        "**Example => 05:** Handoff Input Filter\n"
      ],
      "metadata": {
        "id": "x06Bb4bX9pme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, handoff\n",
        "from agents.extensions import handoff_filters\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "answer_agent = Agent(\n",
        "    name=\"Answer Agent\",\n",
        "    instructions=(\n",
        "        \"You receive clean, pre-filtered history. \"\n",
        "        \"Provide a concise final answer based ONLY on the user's question and direct messages, \"\n",
        "        \"ignoring any previous internal tool-use logs.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "handoff_to_answer = handoff(\n",
        "    agent=answer_agent,\n",
        "    input_filter=handoff_filters.remove_all_tools\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=(\n",
        "        \"Use the available tools to find the answer, then handoff to the Answer Agent \"\n",
        "        \"for a final, clean summary. DO NOT give the answer yourself.\"\n",
        "    ),\n",
        "    handoffs=[handoff_to_answer]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        userInput = input(\"You: \")\n",
        "\n",
        "        if userInput.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        result = await Runner.run(\n",
        "            starting_agent=triage_agent,\n",
        "            input=userInput,\n",
        "        )\n",
        "\n",
        "        print(f\"Current Agent: {result.last_agent.name}\")\n",
        "        print(f\"Output: {result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "g-gZx-hR-OPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Custom Handoff Filter**\n",
        "**Example => 06:** Custom Handoff Filter\n"
      ],
      "metadata": {
        "id": "noFzqURz_Sc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, handoff, HandoffInputData\n",
        "from agents.extensions import handoff_filters\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "def remove_last_two_items(handoff_input_data: HandoffInputData) -> HandoffInputData:\n",
        "    # pre_handoff_items mein pichle messages hote hain.\n",
        "    old_items = handoff_input_data.pre_handoff_items\n",
        "\n",
        "    # Puranay items mein se sirf starting ky items rakheinge, last 2 items hata dengy.\n",
        "    # [:-2] ka matlab hay: shuru se lekar last ki do chor kar.\n",
        "    filtered_items = old_items[:-2]\n",
        "\n",
        "    # HandoffInputData ko modify karne ke liye .clone() use karte hain.\n",
        "    modified_data = handoff_input_data.clone(\n",
        "        pre_handoff_items=filtered_items\n",
        "    )\n",
        "\n",
        "    return modified_data\n",
        "\n",
        "\n",
        "\n",
        "answer_agent = Agent(\n",
        "    name=\"Answer Agent\",\n",
        "    instructions=(\n",
        "        \"You receive clean, pre-filtered history. \"\n",
        "        \"Provide a concise final answer based ONLY on the user's question and direct messages, \"\n",
        "        \"ignoring any previous internal tool-use logs.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "handoff_to_answer = handoff(\n",
        "    agent=answer_agent,\n",
        "    input_filter=remove_last_two_items\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=(\n",
        "        \"Use the available tools to find the answer, then handoff to the Answer Agent \"\n",
        "        \"for a final, clean summary. DO NOT give the answer yourself.\"\n",
        "    ),\n",
        "    handoffs=[handoff_to_answer]\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        userInput = input(\"You: \")\n",
        "\n",
        "        if userInput.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        result = await Runner.run(\n",
        "            starting_agent=triage_agent,\n",
        "            input=userInput,\n",
        "        )\n",
        "\n",
        "        print(f\"Current Agent: {result.last_agent.name}\")\n",
        "        print(f\"Output: {result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "HoFc_WTH_bQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **🔸Recommended prompts**\n"
      ],
      "metadata": {
        "id": "wF31OF8nDhdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner\n",
        "from dotenv import load_dotenv\n",
        "import asyncio\n",
        "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "billing_agent = Agent(\n",
        "    name=\"Billing agent\",\n",
        "    instructions=f\"{RECOMMENDED_PROMPT_PREFIX}\",\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    while True:\n",
        "        userInput = input(\"You: \")\n",
        "\n",
        "        if userInput.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        result = await Runner.run(\n",
        "            starting_agent=billing_agent,\n",
        "            input=userInput,\n",
        "        )\n",
        "\n",
        "        print(f\"Current Agent: {result.last_agent.name}\")\n",
        "        print(f\"Output: {result.final_output}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "NIQ0utuaDl-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}