{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1KrGOXMLady"
      },
      "source": [
        "## ðŸ”¹ **Agents â†’ Output Types**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y openai\n",
        "!pip install --upgrade openai\n",
        "!pip install --upgrade openai-agents\n",
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jJM7UnVI7fZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ”¸Output Types**\n",
        "**Example => 01:** Default Behavior"
      ],
      "metadata": {
        "id": "1RARWu2V63Bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95bdex_MLVsA"
      },
      "outputs": [],
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAi5mH68EimKoRet-Sps-kQpgw0cAQsxe0\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"plain_text\",\n",
        "        instructions=\"You are a helpfull assistant.\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"How are you\",\n",
        "        run_config=config\n",
        "    )\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ”¸Output Types**\n",
        "**Example => 02:**  Explicitly Specifying str"
      ],
      "metadata": {
        "id": "acyCawpiu486"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAi5mH68EimKoRet-Sps-kQpgw0cAQsxe0\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"string_agent\",\n",
        "    instructions=\"you are a helpfull asistant\",\n",
        "    output_type=str\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"Hello how are you ?\",\n",
        "        run_config=config\n",
        "    )\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "IkpevSQxuz_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eDHPiiNO4r9"
      },
      "source": [
        "### **ðŸ”¸Structured Output**\n",
        "**Example => 03:** First Structure Output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner\n",
        "import nest_asyncio\n",
        "from pydantic import BaseModel\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyAi5mH68EimKoRet-Sps-kQpgw0cAQsxe0\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "class UserProfile(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    is_active: bool\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"profile_extractor\",\n",
        "    instructions=\"Extract a user's name, age, and activity status.\",\n",
        "    output_type=UserProfile\n",
        ")\n",
        "\n",
        "async def main():\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"A user named Mesum, 30 years old, who is currently online.\",\n",
        "        run_config=config\n",
        "    )\n",
        "    print(f\"Output: {result.final_output.model_dump()}\")\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "_HHBnJjS7cUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ”¸Structured Output**\n",
        "**Example => 04:** AgentOutputSchemaBase Ko Override Karna"
      ],
      "metadata": {
        "id": "b24FlN1QyKDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, AgentOutputSchemaBase, AgentOutputSchema\n",
        "import nest_asyncio\n",
        "from typing import Any\n",
        "from pydantic import BaseModel\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyCIgATnpmw6AM6qvpLF9MALMLt4-dixWtQ\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "class CustomStrictSchema(AgentOutputSchemaBase, BaseModel):\n",
        "  data: str\n",
        "  is_valid: bool\n",
        "\n",
        "  def name(self) -> str:\n",
        "    return \"CustomStrictSchema\"\n",
        "\n",
        "  def is_plain_text(self) -> bool:\n",
        "    return False\n",
        "\n",
        "  def json_schema(self) -> dict[str, Any]:\n",
        "     return {\n",
        "         type: \"object\",\n",
        "         \"properties\": {\n",
        "             \"data\": {type: \"string\", \"description\": \"A relevant piece of data.\"},\n",
        "             \"is_valid\": {\"type\": \"boolean\", \"description\": \"True if the data is valid.\"}\n",
        "         },\n",
        "         \"required\": [\"data\", \"is_valid\"]\n",
        "     }\n",
        "\n",
        "  def is_strict_json_schema(self) -> bool:\n",
        "     return True\n",
        "\n",
        "  def validate_json(self, json_str: str) -> Any:\n",
        "     try:\n",
        "      adapter = AgentOutputSchema()\n",
        "      validated_object = adapter.validate_json(json_str)\n",
        "      return validated_object\n",
        "     except Exception as e:\n",
        "      raise ValueError(f\"Validation failed for JSON: {json_str}. Error: {e}\")\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"profile_extractor\",\n",
        "    instructions=\"Extract a user's name, age, and activity status.\",\n",
        "    output_type=CustomStrictSchema\n",
        ")\n",
        "\n",
        "async def main():\n",
        "\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"A user named Mesum, 30 years old, who is currently online.\",\n",
        "        run_config=config\n",
        "    )\n",
        "    print(f\"Output: {result.final_output.model_dump()}\")\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "rU7DXH1qyKlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ”¸Structured Output**\n",
        "**Example => 05:** AgentOutputSchema ko use karky auto validate karna"
      ],
      "metadata": {
        "id": "Hkn1VP5xmSpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, AgentOutputSchema\n",
        "import nest_asyncio\n",
        "from typing import Any\n",
        "from pydantic import BaseModel\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyCIgATnpmw6AM6qvpLF9MALMLt4-dixWtQ\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "\n",
        "class Event(BaseModel):\n",
        "    title: str\n",
        "    location: str\n",
        "\n",
        "schema = AgentOutputSchema(output_type=Event)\n",
        "json_blueprint = schema.json_schema()\n",
        "is_strict = schema.is_strict_json_schema()\n",
        "\n",
        "print(\"Schema Blueprint:\")\n",
        "print(json_blueprint)\n",
        "print(f\"Is schema strict? {is_strict}\")\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"profile_extractor\",\n",
        "    instructions=\"Extract a user's name, age, and activity status.\",\n",
        "    output_type=schema\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"A user named Mesum, 30 years old, who is currently online.\",\n",
        "        run_config=config\n",
        "    )\n",
        "    print(f\"Output: {result.final_output.model_dump()}\")\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "ODcxx1pQgL4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ”¸Structured Output**\n",
        "**Example => 06:** Hum validate_json() method ko use karke LLM se mile huwy raw JSON output ko manually check aur parse kar sakte hain."
      ],
      "metadata": {
        "id": "e3vrOxjMnab4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig, Runner, AgentOutputSchema, ModelBehaviorError\n",
        "import nest_asyncio\n",
        "from typing import Any\n",
        "from pydantic import BaseModel\n",
        "\n",
        "nest_asyncio.apply()\n",
        "gemini_api_key = \"AIzaSyCIgATnpmw6AM6qvpLF9MALMLt4-dixWtQ\"\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=client,\n",
        "    tracing_disabled=True\n",
        ")\n",
        "\n",
        "\n",
        "class Address(BaseModel):\n",
        "    street: str\n",
        "    city: str\n",
        "    zip_code: str\n",
        "\n",
        "address_schema = AgentOutputSchema(output_type=Address)\n",
        "valid_json_str = '{\"street\": \"123 Main St\", \"city\": \"Anytown\", \"zip_code\": \"12345\"}'\n",
        "invalid_json_str = '{\"street\": \"456 Oak Ave\", \"city\": \"Somewhere\"}'\n",
        "\n",
        "try:\n",
        "  validated_address = address_schema.validate_json(valid_json_str)\n",
        "  print(f\"Valid JSON: {validated_address}\")\n",
        "except ModelBehaviorError as e:\n",
        "  print(f\"Validation failed for valid JSON: {e}\")\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"profile_extractor\",\n",
        "    instructions=\"Extract a user's name, age, and activity status.\",\n",
        "    output_type=address_schema\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(\n",
        "        starting_agent=agent,\n",
        "        input=\"A user named Mesum, 30 years old, who is currently online.\",\n",
        "        run_config=config\n",
        "    )\n",
        "    print(f\"Output: {result.final_output.model_dump()}\")\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "2gKdKns9nixA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}